[
  {
    "objectID": "archive.html",
    "href": "archive.html",
    "title": "Archive",
    "section": "",
    "text": "Are You Ready When It Fails? Lessons from Network Outages in Reproducible Data Analysis\n\n\n\n\n\n\n\n\nDec 26, 2024\n\n\n\n\n\n\n\nReproducible Analysis Pipeline is akin to Cooking: A Simplified Guide\n\n\n\n\n\n\n\n\nDec 2, 2024\n\n\n\n\n\n\n\nLessons from a Splint: How Non-Reproducibility Hurts Science\n\n\n\n\n\n\n\n\nOct 21, 2024\n\n\n\n\n\n\n\nBeginning with reproducibility in mind\n\n\n\n\n\n\n\n\nOct 9, 2024\n\n\n\n\n\n\n\nFrom Charts to Consistency: My R Journey to Reproducibility\n\n\n\n\n\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\nWhy Making the Same Rasam Matters: A Story from the Kitchen\n\n\n\n\n\n\n\n\nMar 26, 2024\n\n\n\n\n\n\n\nThe Beginner‚Äôs Blueprint: Crafting a Documented Path in Your R Data Analysis Journey\n\n\n\n\n\n\n\n\nJan 9, 2024\n\n\n\n\n\n\n\nReproducibility: A Non-Negotiable Imperative\n\n\n\n\n\n\n\n\nNov 22, 2023\n\n\n\n\n\n\n\nCreate a Comprehensive Report of All Variables in R\n\n\n\n\n\n\n\n\nMay 1, 2023\n\n\n\n\n\n\n\nModern Storytelling: Examining the parallels in Movies and Academic Papers\n\n\n\n\n\n\n\n\nApr 18, 2023\n\n\n\n\n\n\n\nExploring With Intention - Exploratory data analysis for beginners in R\n\n\n\n\n\n\n\n\nMar 29, 2023\n\n\n\n\n\n\n\nBuilding a Foundation for Success: How Reproducibility Practices in R Benefit Beginners\n\n\n\n\n\n\n\n\nMar 29, 2023\n\n\n\n\n\n\n\nClear Paths for Reproducible R: Here Package\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\nMar 24, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "SoundReproSteps",
    "section": "",
    "text": "Are You Ready When It Fails? Lessons from Network Outages in Reproducible Data Analysis\n\n\n\n\n\n\nreproducibility\n\n\nBeginner\n\n\nmaster\n\n\n\n\n\n\n\n\n\nDec 26, 2024\n\n\n4 min\n\n\n\n\n\n\n\nReproducible Analysis Pipeline is akin to Cooking: A Simplified Guide\n\n\n\n\n\n\nreproducibility\n\n\nBeginner\n\n\ncooking\n\n\n\n\n\n\n\n\n\nDec 2, 2024\n\n\n2 min\n\n\n\n\n\n\n\nLessons from a Splint: How Non-Reproducibility Hurts Science\n\n\n\n\n\n\nreproducibility\n\n\nBeginner\n\n\nlogbooks\n\n\n\n\n\n\n\n\n\nOct 21, 2024\n\n\n4 min\n\n\n\n\n\n\n\nBeginning with reproducibility in mind\n\n\n\n\n\n\nreproducibility\n\n\nBeginner\n\n\nBest practices\n\n\n\n\n\n\n\n\n\nOct 9, 2024\n\n\n4 min\n\n\n\n\n\n\n\nFrom Charts to Consistency: My R Journey to Reproducibility\n\n\n\n\n\n\nreproducibility\n\n\nBeginner\n\n\nBest practices\n\n\n\n\n\n\n\n\n\nJul 2, 2024\n\n\n4 min\n\n\n\n\n\n\n\nWhy Making the Same Rasam Matters: A Story from the Kitchen\n\n\n\n\n\n\nreproducibility\n\n\nscience\n\n\nGeneral audience\n\n\nGeneral public\n\n\n\n\n\n\n\n\n\nMar 26, 2024\n\n\n3 min\n\n\n\n\n\n\n\nThe Beginner‚Äôs Blueprint: Crafting a Documented Path in Your R Data Analysis Journey\n\n\n\n\n\n\ndocumentation\n\n\nanalysis\n\n\nbeginners\n\n\n\n\n\n\n\n\n\nJan 9, 2024\n\n\n4 min\n\n\n\n\n\n\n\nReproducibility: A Non-Negotiable Imperative\n\n\n\n\n\n\nreproducibility\n\n\nresearch\n\n\nscience\n\n\n\n\n\n\n\n\n\nNov 22, 2023\n\n\n3 min\n\n\n\n\n\n\n\nCreate a Comprehensive Report of All Variables in R\n\n\n\n\n\n\nEDA\n\n\ndata-overview\n\n\nbeginners\n\n\n\n\n\n\n\n\n\nMay 1, 2023\n\n\n2 min\n\n\n\n\n\n\n\nModern Storytelling: Examining the parallels in Movies and Academic Papers\n\n\n\n\n\n\nwriting\n\n\nresearch\n\n\nbeginners\n\n\n\n\n\n\n\n\n\nApr 18, 2023\n\n\n3 min\n\n\n\n\n\n\n\nExploring With Intention - Exploratory data analysis for beginners in R\n\n\n\n\n\n\nbest-practices\n\n\nEDA\n\n\nbeginners\n\n\n\n\n\n\n\n\n\nMar 29, 2023\n\n\n1 min\n\n\n\n\n\n\n\nBuilding a Foundation for Success: How Reproducibility Practices in R Benefit Beginners\n\n\n\n\n\n\nbest-practices\n\n\natomic-essays\n\n\nbeginners\n\n\n\n\n\n\n\n\n\nMar 29, 2023\n\n\n1 min\n\n\n\n\n\n\n\nClear Paths for Reproducible R: Here Package\n\n\n\n\n\n\nbest-practices\n\n\nhere\n\n\nprojects\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n3 min\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nMar 24, 2023\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dr.¬†Soundarya Soundararajan",
    "section": "",
    "text": "Reproducible research is an essential part of scientific inquiry, and R is a tool that can help us achieve it.\n\nBefore adopting reproducibility, I often found myself returning to a trail of scattered scripts, searching one by one to figure out which ones I was working on. Although I showed up consistently, the struggle to manage my workflow was exhausting. Then, it hit me‚ÄîI was missing the key ingredient that would transform my process: Reproducibility.\nThis is why I advocate for reproducibility as a compelling reason to learn R.\n\nStarting with reproducibility, even as a beginner, makes learning R so much more meaningful and rewarding!"
  },
  {
    "objectID": "posts/benefits-reproducibility/reproducibility-benefits-beginners.html",
    "href": "posts/benefits-reproducibility/reproducibility-benefits-beginners.html",
    "title": "Building a Foundation for Success: How Reproducibility Practices in R Benefit Beginners",
    "section": "",
    "text": "As an advocate for reproducible research, I often wonder if beginners find it challenging to adopt reproducible practices. In this brief essay, I want to remind myself and others how beginners can benefit from such practices.\n\n\n\nMy atomic essay as appeared in Twitter on 29-03-2023\n\n\nLearn more on atomic essays here."
  },
  {
    "objectID": "posts/post-with-code/here.html",
    "href": "posts/post-with-code/here.html",
    "title": "Clear Paths for Reproducible R: Here Package",
    "section": "",
    "text": "This post is an introduction to the here package, a powerful tool that helps maintain best practices in reproducible workflows.\nBefore using the here package I faced two main issues.\nInitially, I thought using a consistent folder structure with RStudio‚Äôs projects 1 would fix the first issue. This did temporarily solve my 1st problem, however, to make matters worse, my work system was fixed and the root directory changed. This added further complexity to my workflow.\nAs a result, I found myself writing separate sets of code to work effectively in both locations.\nI encountered further difficulties when I tried to automate my workflow by sourcing files. Alas, this made me go grrr üò†.\nThe answer to the troubles are in the here package.\n1pacman::p_load(here)\n2here()\n\n\n1\n\nInstalls and loads the package\n\n2\n\nTells you where the root is\n\n\n\n\n[1] \"D:/MyRProjects/SoundReproSteps\"\nüìçBy knowing where the root is helps you write better file paths.\nFor example, let‚Äôs say this is your folder structure.\n‚îú‚îÄ‚îÄ ProjectName.Rproj\n‚îú‚îÄ‚îÄ üìÅData\n‚Äî‚Äî‚Äì ‚îú‚îÄ‚îÄ data_to_use.csv\n‚îú‚îÄ‚îÄ üìÅDocs\n‚Äì ‚Äî‚Äî‚îú‚îÄ‚îÄ example1.R\n‚Äî‚Äî‚Äì ‚îú‚îÄ‚îÄ example2.Rmd"
  },
  {
    "objectID": "posts/post-with-code/here.html#the-key-takeaway-for-reproducible-workflows-is-this",
    "href": "posts/post-with-code/here.html#the-key-takeaway-for-reproducible-workflows-is-this",
    "title": "Clear Paths for Reproducible R: Here Package",
    "section": "The key takeaway for reproducible workflows is this",
    "text": "The key takeaway for reproducible workflows is this\nUse the here package to write relative paths for reading and writing your data and files. This will streamline your workflow, allowing you to work seamlessly across different platforms and eliminating the need to constantly adjust file paths when switching between .R and .Rmd files.\n\nStreamline your workflow with here and say goodbye to path confusion!"
  },
  {
    "objectID": "posts/post-with-code/here.html#footnotes",
    "href": "posts/post-with-code/here.html#footnotes",
    "title": "Clear Paths for Reproducible R: Here Package",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn a previous blog post, I wrote about the importance of taking the first steps when starting a new project.Access it here‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/parallel-movies-research/modernstorytelling.html",
    "href": "posts/parallel-movies-research/modernstorytelling.html",
    "title": "Modern Storytelling: Examining the parallels in Movies and Academic Papers",
    "section": "",
    "text": "TLDR - A good movie and a good academic paper have striking similarities in their structure and impact.\nAcademic writing now requires good storytelling to engage readers effectively(‚ÄúStorytelling in Research‚Äù 2018). Introducing characters and establishing a story arc with conflicts and resolutions creates a memorable experience that enhances the understanding and appreciation of research.\nIf you are new to the storytelling style in research writing, two key elements must not be missed: a hooking introduction and a central theme. A hooking introduction engages readers from the start, while a central theme provides the narrative structure that guides the reader through the research. These two elements are essential starting points for incorporating storytelling into your research writing."
  },
  {
    "objectID": "posts/parallel-movies-research/modernstorytelling.html#hooking-at-the-very-beginning",
    "href": "posts/parallel-movies-research/modernstorytelling.html#hooking-at-the-very-beginning",
    "title": "Modern Storytelling: Examining the parallels in Movies and Academic Papers",
    "section": "Hooking at the very beginning",
    "text": "Hooking at the very beginning\nA good movie grabs your attention within the first ten minutes by portraying polarizing elements and leaving you wondering how these opposing characters will be brought together, creating suspense. Similarly, a well-written academic paper requires a hooking introduction. This can be achieved by using simple language and tailoring it to the central message that the paper conveys. A lengthy and boring introduction indicates that the writer is not clear about what they want to communicate. An excellent introduction keeps the reader engaged in the paper, even if the subject matter is outside their area of expertise. Hooking the reader and maintaining their engagement throughout the paper is crucial."
  },
  {
    "objectID": "posts/parallel-movies-research/modernstorytelling.html#rippling-the-central-message-throughout-the-moviepaper",
    "href": "posts/parallel-movies-research/modernstorytelling.html#rippling-the-central-message-throughout-the-moviepaper",
    "title": "Modern Storytelling: Examining the parallels in Movies and Academic Papers",
    "section": "Rippling the central message throughout the movie/paper",
    "text": "Rippling the central message throughout the movie/paper\nIn a good movie, the central message gains strength and power as the story unfolds. Similarly, a well-written academic paper should gradually ripple the central message throughout the text, gaining momentum from supporting results, and leaving a lasting impact on the reader. A good movie that conveys its central message effectively leaves a lasting impression on the viewer, with all other aspects fading away in comparison. It is like a wave slowly gaining momentum until it hits you and leaves you drenched, and all you can recall is the message. Another effective way to leave a lasting impression is to make the central message the title of the paper.\n\nEach one of these is making a noise, and yet we do not catch it; it is only when they become the big aggregate that we hear. ‚Äî Complete Works of Swami Vivekananda by Swami Vivekananda\n\n\n\n\nPhoto by Photoholgic on Unsplash"
  },
  {
    "objectID": "posts/parallel-movies-research/modernstorytelling.html#accepting-the-limitations",
    "href": "posts/parallel-movies-research/modernstorytelling.html#accepting-the-limitations",
    "title": "Modern Storytelling: Examining the parallels in Movies and Academic Papers",
    "section": "Accepting the limitations",
    "text": "Accepting the limitations\nA good story may have its limitations, but the central message is often so strong that the audience is willing to overlook any flaws. Similarly, a well-written academic paper may have its limitations, but by explicitly acknowledging them and establishing a compelling central theme, the reader is more likely to accept any weaknesses and embrace the central message despite the limitations.\nA great paper and an excellent movie have more in common than you might think, and they both have the power to leave a lasting impression on their audience. It‚Äôs fascinating to see how these two seemingly different forms of storytelling can share many similarities. Can you think of any other parallels between the two? The possibilities are endless, and exploring them further could lead to new insights and perspectives on the art of storytelling."
  },
  {
    "objectID": "posts/2023-05-01-dfsummary/dfsummary.html",
    "href": "posts/2023-05-01-dfsummary/dfsummary.html",
    "title": "Create a Comprehensive Report of All Variables in R",
    "section": "",
    "text": "To effectively analyze data, understanding the characteristics of variables in the dataset is crucial.\nGenerating a comprehensive summary of variables helps to identify duplicates, important variables, and necessary transformations based on their distributions. In this post, I will generate a summary report using the summarytools package in R, and also ahow how to avoid common mistakes. This technique is useful for datasets of any size and facilitates efficient data analysis."
  },
  {
    "objectID": "posts/2023-05-01-dfsummary/dfsummary.html#libraries-required",
    "href": "posts/2023-05-01-dfsummary/dfsummary.html#libraries-required",
    "title": "Create a Comprehensive Report of All Variables in R",
    "section": "Libraries required",
    "text": "Libraries required\n\n# Install pacman if you have not\n# install.packages(\"pacman\")\npacman::p_load(\"summarytools\", \"palmerpenguins\")"
  },
  {
    "objectID": "posts/2023-05-01-dfsummary/dfsummary.html#summarize-the-data",
    "href": "posts/2023-05-01-dfsummary/dfsummary.html#summarize-the-data",
    "title": "Create a Comprehensive Report of All Variables in R",
    "section": "Summarize the data",
    "text": "Summarize the data\n\nview(dfSummary(penguins))"
  },
  {
    "objectID": "posts/2023-05-01-dfsummary/dfsummary.html#output",
    "href": "posts/2023-05-01-dfsummary/dfsummary.html#output",
    "title": "Create a Comprehensive Report of All Variables in R",
    "section": "Output",
    "text": "Output\nThe output appears in the viewer pane, where categorical and continuous variables are charted with bar or histogram formats, respectively.\n\n\n\nScreenshot of the output\n\n\nTo save the output, simply click ‚Äòshow in new window‚Äô and then right-click the opened browser window to save it to the desired location."
  },
  {
    "objectID": "posts/2023-05-01-dfsummary/dfsummary.html#why-this-works",
    "href": "posts/2023-05-01-dfsummary/dfsummary.html#why-this-works",
    "title": "Create a Comprehensive Report of All Variables in R",
    "section": "Why this works?",
    "text": "Why this works?\nI initially developed this summary report during my postdoctoral research, and my supervisor was impressed by its ability to provide a concise, one-page summary of important variables, complete with a graphic overview that is useful for downstream decision-making.\n\nBefore you dive into the depths of data, take flight with a bird‚Äôs eye view of the dataset at hand\n\n\n\n\nPhoto by KAL VISUALS on Unsplash"
  },
  {
    "objectID": "posts/2023-05-01-dfsummary/dfsummary.html#mistake-to-avoid",
    "href": "posts/2023-05-01-dfsummary/dfsummary.html#mistake-to-avoid",
    "title": "Create a Comprehensive Report of All Variables in R",
    "section": "Mistake to avoid",
    "text": "Mistake to avoid\nA common beginner‚Äôs mistake is to use the View() function instead of the view() function (with a small ‚Äòv‚Äô). The former opens the dataset in R, whereas the latter is a function of the summarytools package used to create the output."
  },
  {
    "objectID": "posts/2023-05-23-onEDA/EDA.html",
    "href": "posts/2023-05-23-onEDA/EDA.html",
    "title": "Exploring With Intention - Exploratory data analysis for beginners in R",
    "section": "",
    "text": "Let‚Äôs explore\npacman::p_load(palmerpenguins,tidyverse,\n               report, skimr, summarytools)"
  },
  {
    "objectID": "posts/2023-05-23-onEDA/EDA.html#rough-and-quick",
    "href": "posts/2023-05-23-onEDA/EDA.html#rough-and-quick",
    "title": "Exploring With Intention - Exploratory data analysis for beginners in R",
    "section": "Rough and quick",
    "text": "Rough and quick\n\nstr(penguins) # Far better\n\ntibble [344 √ó 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\nreport(penguins)\n\nThe data contains 344 observations of the following 8 variables:\n\n  - species: 3 levels, namely Adelie (n = 152, 44.19%), Chinstrap (n = 68,\n19.77%) and Gentoo (n = 124, 36.05%)\n  - island: 3 levels, namely Biscoe (n = 168, 48.84%), Dream (n = 124, 36.05%)\nand Torgersen (n = 52, 15.12%)\n  - bill_length_mm: n = 344, Mean = 43.92, SD = 5.46, Median = , MAD = 7.04,\nrange: [32.10, 59.60], Skewness = 0.05, Kurtosis = -0.88, 0.58% missing\n  - bill_depth_mm: n = 344, Mean = 17.15, SD = 1.97, Median = , MAD = 2.22,\nrange: [13.10, 21.50], Skewness = -0.14, Kurtosis = -0.91, 0.58% missing\n  - flipper_length_mm: n = 344, Mean = 200.92, SD = 14.06, Median = , MAD =\n16.31, range: [172, 231], Skewness = 0.35, Kurtosis = -0.98, 0.58% missing\n  - body_mass_g: n = 344, Mean = 4201.75, SD = 801.95, Median = , MAD = 889.56,\nrange: [2700, 6300], Skewness = 0.47, Kurtosis = -0.72, 0.58% missing\n  - sex: 2 levels, namely female (n = 165, 47.97%), male (n = 168, 48.84%) and\nmissing (n = 11, 3.20%)\n  - year: n = 344, Mean = 2008.03, SD = 0.82, Median = 2008.00, MAD = 1.48,\nrange: [2007, 2009], Skewness = -0.05, Kurtosis = -1.50, 0% missing"
  },
  {
    "objectID": "posts/2023-05-23-onEDA/EDA.html#neat-and-quick",
    "href": "posts/2023-05-23-onEDA/EDA.html#neat-and-quick",
    "title": "Exploring With Intention - Exploratory data analysis for beginners in R",
    "section": "Neat and quick",
    "text": "Neat and quick\n\nskim(penguins)\n\n\nData summary\n\n\nName\npenguins\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nspecies\n0\n1.00\nFALSE\n3\nAde: 152, Gen: 124, Chi: 68\n\n\nisland\n0\n1.00\nFALSE\n3\nBis: 168, Dre: 124, Tor: 52\n\n\nsex\n11\n0.97\nFALSE\n2\nmal: 168, fem: 165\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nbill_length_mm\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\n‚ñÉ‚ñá‚ñá‚ñÜ‚ñÅ\n\n\nbill_depth_mm\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\n‚ñÖ‚ñÖ‚ñá‚ñá‚ñÇ\n\n\nflipper_length_mm\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\n‚ñÇ‚ñá‚ñÉ‚ñÖ‚ñÇ\n\n\nbody_mass_g\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\n‚ñÉ‚ñá‚ñÜ‚ñÉ‚ñÇ\n\n\nyear\n0\n1.00\n2008.03\n0.82\n2007.0\n2007.00\n2008.00\n2009.0\n2009.0\n‚ñá‚ñÅ‚ñá‚ñÅ‚ñá\n\n\n\n\n\n\ndfSummary(penguins)\n\nData Frame Summary  \npenguins  \nDimensions: 344 x 8  \nDuplicates: 0  \n\n--------------------------------------------------------------------------------------------------------------------\nNo   Variable            Stats / Values             Freqs (% of Valid)    Graph                 Valid      Missing  \n---- ------------------- -------------------------- --------------------- --------------------- ---------- ---------\n1    species             1. Adelie                  152 (44.2%)           IIIIIIII              344        0        \n     [factor]            2. Chinstrap                68 (19.8%)           III                   (100.0%)   (0.0%)   \n                         3. Gentoo                  124 (36.0%)           IIIIIII                                   \n\n2    island              1. Biscoe                  168 (48.8%)           IIIIIIIII             344        0        \n     [factor]            2. Dream                   124 (36.0%)           IIIIIII               (100.0%)   (0.0%)   \n                         3. Torgersen                52 (15.1%)           III                                       \n\n3    bill_length_mm      Mean (sd) : 43.9 (5.5)     164 distinct values       .     . :         342        2        \n     [numeric]           min &lt; med &lt; max:                                   . : : : : :         (99.4%)    (0.6%)   \n                         32.1 &lt; 44.5 &lt; 59.6                                 : : : : : :                             \n                         IQR (CV) : 9.3 (0.1)                               : : : : : : .                           \n                                                                          : : : : : : : : .                         \n\n4    bill_depth_mm       Mean (sd) : 17.2 (2)       80 distinct values              :           342        2        \n     [numeric]           min &lt; med &lt; max:                                         : :           (99.4%)    (0.6%)   \n                         13.1 &lt; 17.3 &lt; 21.5                                 : . : : : .                             \n                         IQR (CV) : 3.1 (0.1)                             . : : : : : :                             \n                                                                          : : : : : : : . .                         \n\n5    flipper_length_mm   Mean (sd) : 200.9 (14.1)   55 distinct values          :               342        2        \n     [integer]           min &lt; med &lt; max:                                     . :               (99.4%)    (0.6%)   \n                         172 &lt; 197 &lt; 231                                      : : :   . .                           \n                         IQR (CV) : 23 (0.1)                                . : : :   : : :                         \n                                                                            : : : : : : : : :                       \n\n6    body_mass_g         Mean (sd) : 4201.8 (802)   94 distinct values        :                 342        2        \n     [integer]           min &lt; med &lt; max:                                   . :                 (99.4%)    (0.6%)   \n                         2700 &lt; 4050 &lt; 6300                                 : : : :                                 \n                         IQR (CV) : 1200 (0.2)                              : : : : : .                             \n                                                                          . : : : : : :                             \n\n7    sex                 1. female                  165 (49.5%)           IIIIIIIII             333        11       \n     [factor]            2. male                    168 (50.5%)           IIIIIIIIII            (96.8%)    (3.2%)   \n\n8    year                Mean (sd) : 2008 (0.8)     2007 : 110 (32.0%)    IIIIII                344        0        \n     [integer]           min &lt; med &lt; max:           2008 : 114 (33.1%)    IIIIII                (100.0%)   (0.0%)   \n                         2007 &lt; 2008 &lt; 2009         2009 : 120 (34.9%)    IIIIII                                    \n                         IQR (CV) : 2 (0)                                                                           \n--------------------------------------------------------------------------------------------------------------------\n\n#view(dfSummary(penguins))"
  },
  {
    "objectID": "posts/2023-05-23-onEDA/EDA.html#for-the-dataset",
    "href": "posts/2023-05-23-onEDA/EDA.html#for-the-dataset",
    "title": "Exploring With Intention - Exploratory data analysis for beginners in R",
    "section": "For the dataset",
    "text": "For the dataset\n\nRough and quick\n\nstr(penguins) # Far better\n\ntibble [344 √ó 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\nreport(penguins)\n\nThe data contains 344 observations of the following 8 variables:\n\n  - species: 3 levels, namely Adelie (n = 152, 44.19%), Chinstrap (n = 68,\n19.77%) and Gentoo (n = 124, 36.05%)\n  - island: 3 levels, namely Biscoe (n = 168, 48.84%), Dream (n = 124, 36.05%)\nand Torgersen (n = 52, 15.12%)\n  - bill_length_mm: n = 344, Mean = 43.92, SD = 5.46, Median = , MAD = 7.04,\nrange: [32.10, 59.60], Skewness = 0.05, Kurtosis = -0.88, 0.58% missing\n  - bill_depth_mm: n = 344, Mean = 17.15, SD = 1.97, Median = , MAD = 2.22,\nrange: [13.10, 21.50], Skewness = -0.14, Kurtosis = -0.91, 0.58% missing\n  - flipper_length_mm: n = 344, Mean = 200.92, SD = 14.06, Median = , MAD =\n16.31, range: [172, 231], Skewness = 0.35, Kurtosis = -0.98, 0.58% missing\n  - body_mass_g: n = 344, Mean = 4201.75, SD = 801.95, Median = , MAD = 889.56,\nrange: [2700, 6300], Skewness = 0.47, Kurtosis = -0.72, 0.58% missing\n  - sex: 2 levels, namely female (n = 165, 47.97%), male (n = 168, 48.84%) and\nmissing (n = 11, 3.20%)\n  - year: n = 344, Mean = 2008.03, SD = 0.82, Median = 2008.00, MAD = 1.48,\nrange: [2007, 2009], Skewness = -0.05, Kurtosis = -1.50, 0% missing\n\npsych::describe(penguins)\n\n                  vars   n    mean     sd  median trimmed    mad    min    max\nspecies*             1 344    1.92   0.89    2.00    1.90   1.48    1.0    3.0\nisland*              2 344    1.66   0.73    2.00    1.58   1.48    1.0    3.0\nbill_length_mm       3 342   43.92   5.46   44.45   43.91   7.04   32.1   59.6\nbill_depth_mm        4 342   17.15   1.97   17.30   17.17   2.22   13.1   21.5\nflipper_length_mm    5 342  200.92  14.06  197.00  200.34  16.31  172.0  231.0\nbody_mass_g          6 342 4201.75 801.95 4050.00 4154.01 889.56 2700.0 6300.0\nsex*                 7 333    1.50   0.50    2.00    1.51   0.00    1.0    2.0\nyear                 8 344 2008.03   0.82 2008.00 2008.04   1.48 2007.0 2009.0\n                   range  skew kurtosis    se\nspecies*             2.0  0.16    -1.73  0.05\nisland*              2.0  0.61    -0.91  0.04\nbill_length_mm      27.5  0.05    -0.89  0.30\nbill_depth_mm        8.4 -0.14    -0.92  0.11\nflipper_length_mm   59.0  0.34    -1.00  0.76\nbody_mass_g       3600.0  0.47    -0.74 43.36\nsex*                 1.0 -0.02    -2.01  0.03\nyear                 2.0 -0.05    -1.51  0.04\n\n\n\n\nNeat and quick\n\nskim(penguins)\n\n\nData summary\n\n\nName\npenguins\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nspecies\n0\n1.00\nFALSE\n3\nAde: 152, Gen: 124, Chi: 68\n\n\nisland\n0\n1.00\nFALSE\n3\nBis: 168, Dre: 124, Tor: 52\n\n\nsex\n11\n0.97\nFALSE\n2\nmal: 168, fem: 165\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nbill_length_mm\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\n‚ñÉ‚ñá‚ñá‚ñÜ‚ñÅ\n\n\nbill_depth_mm\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\n‚ñÖ‚ñÖ‚ñá‚ñá‚ñÇ\n\n\nflipper_length_mm\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\n‚ñÇ‚ñá‚ñÉ‚ñÖ‚ñÇ\n\n\nbody_mass_g\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\n‚ñÉ‚ñá‚ñÜ‚ñÉ‚ñÇ\n\n\nyear\n0\n1.00\n2008.03\n0.82\n2007.0\n2007.00\n2008.00\n2009.0\n2009.0\n‚ñá‚ñÅ‚ñá‚ñÅ‚ñá\n\n\n\n\npenguins |&gt; \n        group_by(species) |&gt; \n        skim()\n\n\nData summary\n\n\nName\ngroup_by(penguins, specie‚Ä¶\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n2\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nspecies\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nspecies\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nisland\nAdelie\n0\n1.00\nFALSE\n3\nDre: 56, Tor: 52, Bis: 44\n\n\nisland\nChinstrap\n0\n1.00\nFALSE\n1\nDre: 68, Bis: 0, Tor: 0\n\n\nisland\nGentoo\n0\n1.00\nFALSE\n1\nBis: 124, Dre: 0, Tor: 0\n\n\nsex\nAdelie\n6\n0.96\nFALSE\n2\nfem: 73, mal: 73\n\n\nsex\nChinstrap\n0\n1.00\nFALSE\n2\nfem: 34, mal: 34\n\n\nsex\nGentoo\n5\n0.96\nFALSE\n2\nmal: 61, fem: 58\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nspecies\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nbill_length_mm\nAdelie\n1\n0.99\n38.79\n2.66\n32.1\n36.75\n38.80\n40.75\n46.0\n‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñÅ\n\n\nbill_length_mm\nChinstrap\n0\n1.00\n48.83\n3.34\n40.9\n46.35\n49.55\n51.08\n58.0\n‚ñÇ‚ñá‚ñá‚ñÖ‚ñÅ\n\n\nbill_length_mm\nGentoo\n1\n0.99\n47.50\n3.08\n40.9\n45.30\n47.30\n49.55\n59.6\n‚ñÉ‚ñá‚ñÜ‚ñÅ‚ñÅ\n\n\nbill_depth_mm\nAdelie\n1\n0.99\n18.35\n1.22\n15.5\n17.50\n18.40\n19.00\n21.5\n‚ñÇ‚ñÜ‚ñá‚ñÉ‚ñÅ\n\n\nbill_depth_mm\nChinstrap\n0\n1.00\n18.42\n1.14\n16.4\n17.50\n18.45\n19.40\n20.8\n‚ñÖ‚ñá‚ñá‚ñÜ‚ñÇ\n\n\nbill_depth_mm\nGentoo\n1\n0.99\n14.98\n0.98\n13.1\n14.20\n15.00\n15.70\n17.3\n‚ñÖ‚ñá‚ñá‚ñÜ‚ñÇ\n\n\nflipper_length_mm\nAdelie\n1\n0.99\n189.95\n6.54\n172.0\n186.00\n190.00\n195.00\n210.0\n‚ñÅ‚ñÜ‚ñá‚ñÖ‚ñÅ\n\n\nflipper_length_mm\nChinstrap\n0\n1.00\n195.82\n7.13\n178.0\n191.00\n196.00\n201.00\n212.0\n‚ñÅ‚ñÖ‚ñá‚ñÖ‚ñÇ\n\n\nflipper_length_mm\nGentoo\n1\n0.99\n217.19\n6.48\n203.0\n212.00\n216.00\n221.00\n231.0\n‚ñÇ‚ñá‚ñá‚ñÜ‚ñÉ\n\n\nbody_mass_g\nAdelie\n1\n0.99\n3700.66\n458.57\n2850.0\n3350.00\n3700.00\n4000.00\n4775.0\n‚ñÖ‚ñá‚ñá‚ñÉ‚ñÇ\n\n\nbody_mass_g\nChinstrap\n0\n1.00\n3733.09\n384.34\n2700.0\n3487.50\n3700.00\n3950.00\n4800.0\n‚ñÅ‚ñÖ‚ñá‚ñÉ‚ñÅ\n\n\nbody_mass_g\nGentoo\n1\n0.99\n5076.02\n504.12\n3950.0\n4700.00\n5000.00\n5500.00\n6300.0\n‚ñÉ‚ñá‚ñá‚ñá‚ñÇ\n\n\nyear\nAdelie\n0\n1.00\n2008.01\n0.82\n2007.0\n2007.00\n2008.00\n2009.00\n2009.0\n‚ñá‚ñÅ‚ñá‚ñÅ‚ñá\n\n\nyear\nChinstrap\n0\n1.00\n2007.97\n0.86\n2007.0\n2007.00\n2008.00\n2009.00\n2009.0\n‚ñá‚ñÅ‚ñÜ‚ñÅ‚ñá\n\n\nyear\nGentoo\n0\n1.00\n2008.08\n0.79\n2007.0\n2007.00\n2008.00\n2009.00\n2009.0\n‚ñÜ‚ñÅ‚ñá‚ñÅ‚ñá\n\n\n\n\n\n\ndfSummary(penguins)\n\nData Frame Summary  \npenguins  \nDimensions: 344 x 8  \nDuplicates: 0  \n\n--------------------------------------------------------------------------------------------------------------------\nNo   Variable            Stats / Values             Freqs (% of Valid)    Graph                 Valid      Missing  \n---- ------------------- -------------------------- --------------------- --------------------- ---------- ---------\n1    species             1. Adelie                  152 (44.2%)           IIIIIIII              344        0        \n     [factor]            2. Chinstrap                68 (19.8%)           III                   (100.0%)   (0.0%)   \n                         3. Gentoo                  124 (36.0%)           IIIIIII                                   \n\n2    island              1. Biscoe                  168 (48.8%)           IIIIIIIII             344        0        \n     [factor]            2. Dream                   124 (36.0%)           IIIIIII               (100.0%)   (0.0%)   \n                         3. Torgersen                52 (15.1%)           III                                       \n\n3    bill_length_mm      Mean (sd) : 43.9 (5.5)     164 distinct values       .     . :         342        2        \n     [numeric]           min &lt; med &lt; max:                                   . : : : : :         (99.4%)    (0.6%)   \n                         32.1 &lt; 44.5 &lt; 59.6                                 : : : : : :                             \n                         IQR (CV) : 9.3 (0.1)                               : : : : : : .                           \n                                                                          : : : : : : : : .                         \n\n4    bill_depth_mm       Mean (sd) : 17.2 (2)       80 distinct values              :           342        2        \n     [numeric]           min &lt; med &lt; max:                                         : :           (99.4%)    (0.6%)   \n                         13.1 &lt; 17.3 &lt; 21.5                                 : . : : : .                             \n                         IQR (CV) : 3.1 (0.1)                             . : : : : : :                             \n                                                                          : : : : : : : . .                         \n\n5    flipper_length_mm   Mean (sd) : 200.9 (14.1)   55 distinct values          :               342        2        \n     [integer]           min &lt; med &lt; max:                                     . :               (99.4%)    (0.6%)   \n                         172 &lt; 197 &lt; 231                                      : : :   . .                           \n                         IQR (CV) : 23 (0.1)                                . : : :   : : :                         \n                                                                            : : : : : : : : :                       \n\n6    body_mass_g         Mean (sd) : 4201.8 (802)   94 distinct values        :                 342        2        \n     [integer]           min &lt; med &lt; max:                                   . :                 (99.4%)    (0.6%)   \n                         2700 &lt; 4050 &lt; 6300                                 : : : :                                 \n                         IQR (CV) : 1200 (0.2)                              : : : : : .                             \n                                                                          . : : : : : :                             \n\n7    sex                 1. female                  165 (49.5%)           IIIIIIIII             333        11       \n     [factor]            2. male                    168 (50.5%)           IIIIIIIIII            (96.8%)    (3.2%)   \n\n8    year                Mean (sd) : 2008 (0.8)     2007 : 110 (32.0%)    IIIIII                344        0        \n     [integer]           min &lt; med &lt; max:           2008 : 114 (33.1%)    IIIIII                (100.0%)   (0.0%)   \n                         2007 &lt; 2008 &lt; 2009         2009 : 120 (34.9%)    IIIIII                                    \n                         IQR (CV) : 2 (0)                                                                           \n--------------------------------------------------------------------------------------------------------------------\n\n#view(dfSummary(penguins))"
  },
  {
    "objectID": "posts/2023-05-23-onEDA/EDA.html#for-individual-variables",
    "href": "posts/2023-05-23-onEDA/EDA.html#for-individual-variables",
    "title": "Exploring With Intention - Exploratory data analysis for beginners in R",
    "section": "For individual variables",
    "text": "For individual variables\n\nContinuous variables\nboxplots histograms/density plots"
  },
  {
    "objectID": "posts/2023-05-23-onEDA/EDA.html#shiny-app---interactive",
    "href": "posts/2023-05-23-onEDA/EDA.html#shiny-app---interactive",
    "title": "Exploring With Intention - Exploratory data analysis for beginners in R",
    "section": "sHINY APP - Interactive",
    "text": "sHINY APP - Interactive\nhttps://jgassen.shinyapps.io/expand/ # but I am unable to use this\n\nlibrary(ExPanDaR)\n\nWarning: package 'ExPanDaR' was built under R version 4.2.3\n\n#ExPanD(penguins)"
  },
  {
    "objectID": "posts/2023-11-22-reproducibility/reproducibility.html",
    "href": "posts/2023-11-22-reproducibility/reproducibility.html",
    "title": "Reproducibility: A Non-Negotiable Imperative",
    "section": "",
    "text": "In the dynamic realm of scientific research, reproducibility stands as an unwavering pillar‚Äîa fundamental requirement rather than a dispensable luxury.\n\n\n\n\nPhoto by Angela Roma in Pexels\n\n\nA common misconception prevails, suggesting that computational reproducibility is an indulgence that can be overlooked, especially in resource-scarce settings. In my humble opinion, such a perception poses a significant hurdle to scientific progress. Emphasizing reproducibility is not a superfluous endeavor; instead, it is a crucial step toward ensuring the credibility and reliability of scientific findings.\n\nThe absence of reproducibility not only undermines the integrity of scientific endeavors but also obstructs the path to authentic contributions in the field.\n\n\n\nTo foster a deeper understanding of the importance of reproducibility, it‚Äôs essential to address the resistance that often surrounds this concept. Inspired by Bruno Rodrigues‚Äô insightful observations in the realm of reproducible pipelines in R, it becomes evident that resistance stems from a lack of comprehension of reproducibility‚Äôs inherent power.\nWhile the acknowledgment of its tedious nature might deter some, it is crucial to recognize that the benefits far outweigh the challenges. Rodrigues‚Äô work sheds light on the transformative potential of reproducibility, showcasing how it can not only enhance the credibility of research but also contribute to the overall advancement of scientific knowledge.\n\n\n\nTo navigate the landscape of reproducibility effectively, it is imperative to prioritize the establishment of foundational reproducible pipelines. These pipelines serve as the bedrock for long-term progress, offering a structured approach to scientific inquiry.\n\nOnce in place, reproducible pipelines facilitate iterative improvements, allowing researchers to build upon their work systematically.\n\nThe litmus test for scientific rigor lies in the ability to accurately recreate recent analyses down to the decimal point. Success in this task is contingent upon reflecting on the time it took‚Äîboth without and with a laid-down pipeline.\n\n\n\nAs we delve into the realm of scientific inquiry, the litmus test becomes a call to action. Can you confidently reproduce recent analyses, validating the robustness of your findings? It‚Äôs a challenge worth undertaking, as success in this endeavor not only enhances the reliability of your research but also contributes to the collective strength of scientific knowledge.\n\nReproducibility is not merely a check box in the scientific process; it is the cornerstone that fortifies the very foundation of credible and impactful research.\n\nAs we embrace the non-negotiable imperative of reproducibility, we pave the way for a future where scientific contributions are not just profound but enduring.\nSuggested readings on reproducibility:\n\nA Student‚Äôs Guide to Open Science by Charlotte Pennington\nReproducible Research: A Retrospective by Roger Peng and Stephanie Hicks (Have you tried Dr.¬†Peng‚Äôs course on Reproducible Research?)\nBuilding reproducible analytical pipelines with R by Bruno Rodrigues\n\n\n\n\nOne of my simple twitter threads focusing on 4 mistakes in reproducibility while working with R"
  },
  {
    "objectID": "posts/2023-11-22-reproducibility/reproducibility.html#breaking-down-resistance-insights-from-rodrigues",
    "href": "posts/2023-11-22-reproducibility/reproducibility.html#breaking-down-resistance-insights-from-rodrigues",
    "title": "Reproducibility: A Non-Negotiable Imperative",
    "section": "",
    "text": "To foster a deeper understanding of the importance of reproducibility, it‚Äôs essential to address the resistance that often surrounds this concept. Inspired by Bruno Rodrigues‚Äô insightful observations in the realm of reproducible pipelines in R, it becomes evident that resistance stems from a lack of comprehension of reproducibility‚Äôs inherent power.\nWhile the acknowledgment of its tedious nature might deter some, it is crucial to recognize that the benefits far outweigh the challenges. Rodrigues‚Äô work sheds light on the transformative potential of reproducibility, showcasing how it can not only enhance the credibility of research but also contribute to the overall advancement of scientific knowledge."
  },
  {
    "objectID": "posts/2023-11-22-reproducibility/reproducibility.html#establishing-foundations-the-significance-of-pipelines",
    "href": "posts/2023-11-22-reproducibility/reproducibility.html#establishing-foundations-the-significance-of-pipelines",
    "title": "Reproducibility: A Non-Negotiable Imperative",
    "section": "",
    "text": "To navigate the landscape of reproducibility effectively, it is imperative to prioritize the establishment of foundational reproducible pipelines. These pipelines serve as the bedrock for long-term progress, offering a structured approach to scientific inquiry.\n\nOnce in place, reproducible pipelines facilitate iterative improvements, allowing researchers to build upon their work systematically.\n\nThe litmus test for scientific rigor lies in the ability to accurately recreate recent analyses down to the decimal point. Success in this task is contingent upon reflecting on the time it took‚Äîboth without and with a laid-down pipeline."
  },
  {
    "objectID": "posts/2023-11-22-reproducibility/reproducibility.html#can-you-take-the-litmus-test",
    "href": "posts/2023-11-22-reproducibility/reproducibility.html#can-you-take-the-litmus-test",
    "title": "Reproducibility: A Non-Negotiable Imperative",
    "section": "",
    "text": "As we delve into the realm of scientific inquiry, the litmus test becomes a call to action. Can you confidently reproduce recent analyses, validating the robustness of your findings? It‚Äôs a challenge worth undertaking, as success in this endeavor not only enhances the reliability of your research but also contributes to the collective strength of scientific knowledge.\n\nReproducibility is not merely a check box in the scientific process; it is the cornerstone that fortifies the very foundation of credible and impactful research.\n\nAs we embrace the non-negotiable imperative of reproducibility, we pave the way for a future where scientific contributions are not just profound but enduring.\nSuggested readings on reproducibility:\n\nA Student‚Äôs Guide to Open Science by Charlotte Pennington\nReproducible Research: A Retrospective by Roger Peng and Stephanie Hicks (Have you tried Dr.¬†Peng‚Äôs course on Reproducible Research?)\nBuilding reproducible analytical pipelines with R by Bruno Rodrigues\n\n\n\n\nOne of my simple twitter threads focusing on 4 mistakes in reproducibility while working with R"
  },
  {
    "objectID": "posts/2024-01-09-logr/logr.html",
    "href": "posts/2024-01-09-logr/logr.html",
    "title": "The Beginner‚Äôs Blueprint: Crafting a Documented Path in Your R Data Analysis Journey",
    "section": "",
    "text": "This post offers a disciplined approach to maintaining research logs and a proactive mindset for efficient and standardized data analysis sessions.\nWhen I was asked for a detailed analysis conducted last month, I faced two challenges. The steps were really detailed, making a lot of decisions necessary, and remembering the exact process a month later was tough. So, I turned to my log files.\nI keep detailed logs of every step in my analysis. While my main results file has the big decisions, the log files are like prompts, capturing every little thing with timestamps. Even though I could remember the main process, the detailed parts were much clearer in my log files than in my memory.\nMaintaining these logs with the logr package (Bosak 2022) turned out to be a smart move. Writing things down as I go makes it much easier than trying to recall everything later. This idea aligns with Long‚Äôs law of documentation:\nI learned this from J. Scott Long‚Äôs Stata book(Long 2008), a great resource, especially for those learning to code. Following this principle, I only wrap up an analysis session when I‚Äôm confident that the key details are safely stored in my log files.\nThis is a typical analysis session simplified."
  },
  {
    "objectID": "posts/2024-01-09-logr/logr.html#data",
    "href": "posts/2024-01-09-logr/logr.html#data",
    "title": "Logging in analysis",
    "section": "Data",
    "text": "Data\n\npacman::p_load(\"logr\",\"palmerpenguins\",\"tidyverse\")"
  },
  {
    "objectID": "posts/2024-01-09-logr/logr.html#section",
    "href": "posts/2024-01-09-logr/logr.html#section",
    "title": "Logging in analysis",
    "section": "",
    "text": "penguins |&gt; \n        count(species)\n\n# A tibble: 3 √ó 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\n\npenguins |&gt; \n        ggplot(aes(species,bill_length_mm,fill=species))+\n        geom_boxplot()\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`)."
  },
  {
    "objectID": "posts/2024-01-09-logr/logr.html#packages",
    "href": "posts/2024-01-09-logr/logr.html#packages",
    "title": "The Beginner‚Äôs Blueprint: Crafting a Documented Path in Your R Data Analysis Journey",
    "section": "Packages",
    "text": "Packages\n\n```{r}\n#| message: false\n#| warning: false\npacman::p_load(\"logr\",\"here\",\"palmerpenguins\",\"tidyverse\")\n```"
  },
  {
    "objectID": "posts/2024-01-09-logr/logr.html#counting-the-species",
    "href": "posts/2024-01-09-logr/logr.html#counting-the-species",
    "title": "The Beginner‚Äôs Blueprint: Crafting a Documented Path in Your R Data Analysis Journey",
    "section": "Counting the species",
    "text": "Counting the species\n\n```{r}\n#| message: false\n#| warning: false\npenguins |&gt; \n        count(species)\n```\n\n# A tibble: 3 √ó 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124"
  },
  {
    "objectID": "posts/2024-01-09-logr/logr.html#dataviz",
    "href": "posts/2024-01-09-logr/logr.html#dataviz",
    "title": "The Beginner‚Äôs Blueprint: Crafting a Documented Path in Your R Data Analysis Journey",
    "section": "Dataviz",
    "text": "Dataviz\n\n```{r}\n#| message: false\n#| warning: false\npenguins |&gt; \n        ggplot(aes(species,bill_length_mm,fill=species))+\n        geom_boxplot()\n```\n\n\n\n\n\n\n\n\n\nWith different colors\n\n```{r}\n#| message: false\n#| warning: false\npenguins |&gt; \n        ggplot(aes(species,bill_length_mm,fill=species))+\n        geom_boxplot()+\n        scale_fill_manual(values = c(\n                \"midnightblue\", \"orange\", \"seagreen\"\n        ))+\n        theme_minimal()\n```\n\n\n\n\n\n\n\n\nAs I tackle this, I open an R script file and immediately begin jotting down my logs. Check out the script of my log file capturing the entire analysis session below.\n\n\n\nScript of my log file\n\n\nEngaging in this process, I initiate an R script file and promptly commence logging each step. Witness the script of my log file documenting the entire analysis session below. Running this script in parallel with my analysis generates and populates a log output file. I‚Äôve included screenshots of it for your reference below."
  },
  {
    "objectID": "posts/2024-01-09-logr/logr.html#how-i-learnt-to-do-it-better",
    "href": "posts/2024-01-09-logr/logr.html#how-i-learnt-to-do-it-better",
    "title": "The Beginner‚Äôs Blueprint: Crafting a Documented Path in Your R Data Analysis Journey",
    "section": "How I learnt to do it better",
    "text": "How I learnt to do it better\n\nReproducible Logging Script:\n\nI‚Äôve established a fundamental script that serves as my go-to template. Every time I embark on an R project for analysis, I simply copy and integrate this foundational script into my log file. This practice ensures a consistent and reproducible structure for my logs, streamlining the documentation process and maintaining clarity throughout various analyses.\n\nTNT - The Next Thing Approach:\n\nDrawing inspiration from the Getting Things Done (GTD) concept, I conclude each of my log files with a TNT section‚ÄîThe Next Thing. This forward-looking approach acts as a reminder for my next steps in the analysis. When I resume my work, I seamlessly pick up where I left off, enhancing efficiency and maintaining a smooth workflow. By incorporating these two practices, I not only establish a standardized logging procedure but also adopt a proactive mindset for subsequent analytical sessions."
  },
  {
    "objectID": "posts/2024-01-09-logr/logr.html#takeaway",
    "href": "posts/2024-01-09-logr/logr.html#takeaway",
    "title": "The Beginner‚Äôs Blueprint: Crafting a Documented Path in Your R Data Analysis Journey",
    "section": "Takeaway",
    "text": "Takeaway\nThe concept of research logs, as elucidated by Scott Long in his book on the workflow of data analysis using Stata, made a lasting impression on my approach to work. Long emphasizes the pivotal role of logging in keeping the work on track, defining log files as a comprehensive ‚Äúrecord of what you have done, why you did it, and how you did that.‚Äù (Long 2008) In aligning with this philosophy, the ‚Äúlogr‚Äù package has proven instrumental in seamlessly implementing and maintaining this disciplined logging process. It has not only enabled me to adhere to Long‚Äôs principles but has significantly enhanced the efficiency and reproducibility of my data analysis endeavors.\nRead the full documentation of logr package here."
  },
  {
    "objectID": "posts/2024-03-26-reproSimplified/Reproducibility-Simplified.html",
    "href": "posts/2024-03-26-reproSimplified/Reproducibility-Simplified.html",
    "title": "Why Making the Same Rasam Matters: A Story from the Kitchen",
    "section": "",
    "text": "Reproducibility simplified for the general audience\nI recently gave a talk on reproducibility in science, which you can watch here. While my family and friends enjoyed the presentation, they expressed a desire for a simpler explanation. With this feedback in mind, I‚Äôve attempted to distill the essence of reproducibility into a story that‚Äôs easier to grasp.\n\nI‚Äôve always loved cooking, especially how different ingredients mix to create a unique dish. This could be anything from baking a cake to making a traditional South Indian sambar. My grandmother, an amazing cook in our family, once said something interesting about rasam, a popular soup: if you give ten people the same ingredients, they will make ten different types of rasam.\nWhat she meant was simple but important ‚Äì it‚Äôs hard to make the exact same dish every time, and that teaches us something about science too.\n\n\n\nPhoto by Pixabay: https://www.pexels.com/photo/two-teal-ceramic-bowls-262947/\n\n\nLet‚Äôs talk about making rasam the same way every time and why it‚Äôs important. In cooking, different versions of rasam can be fun. But in science, we want results to be the same if we do the same experiment. This helps us trust the results. Imagine if someone says they made rasam, but it tastes like sambar ‚Äì that‚Äôs a mix-up we want to avoid. If everyone understands the recipe the same way, then they can all make the same rasam. This is similar in science, where we want experiments to give us the same results every time.\n\n‚ÄúThe best way to know if something is true is to check it more than once.‚Äù\n\nReproducibility is a big word that means ‚Äúcan we get the same result (rasam) again?‚Äù This is very important in science. If one person‚Äôs experiment gives a certain result, other people should be able to do the same experiment and get the same result. This is like ensuring that if you follow the recipe, you should end up with the rasam you wanted to make.\n\nJust like we double-check our answers in an exam, scientists double-check their experiments.\n\nBut here‚Äôs the issue: not all scientific experiments give the same results when repeated. This is like when someone can‚Äôt make rasam the same way twice. This is a problem in science because if results can‚Äôt be repeated, it can lead to wasted money and even dangerous mistakes in serious fields like medicine.\nI talked about this issue because we need better ways to do science, just like we have clear recipes in cooking. I suggested these three steps we should follow in science, just like in the kitchen:\n\nClear Counters: Just like you need a clean kitchen to cook well, scientists need to organize their data and materials clearly.\nRecipe Book: Writing down every step of an experiment is important. This is like writing down each step in a recipe so someone else can make the same rasam.\nFresh vs.¬†Used Ingredients: In cooking, we keep fresh and used ingredients separate. Scientists should do the same with their data to avoid mix-ups.\n\nI also talked about sharing our recipes, just like sharing our experiments. If someone wants to make rasam, they can follow a recipe. I touched upon a software called R, which will help scientists do reproducible research.\nSo, understanding and sharing how we do things is key, whether we‚Äôre making a rasam or doing a science experiment. This helps everyone know they‚Äôre on the right track.\n\nLet‚Äôs keep science as straightforward and reliable as a good recipe ‚Äì that way, everyone can trust the results, just like they trust a good meal."
  },
  {
    "objectID": "posts/2024-07-02-rforreproducibility/rforreproducibility.html",
    "href": "posts/2024-07-02-rforreproducibility/rforreproducibility.html",
    "title": "From Charts to Consistency: My R Journey to Reproducibility",
    "section": "",
    "text": "In this post, I provide beginners with practical tips to embrace reproducibility while using R.\nI see a lot of folks stumbling in R. They find it difficult, complex, and intimidating. They start their data analysis or visualization and find it very hard to proceed. They give up and move to other tools. There is a secret to approach R in a better way. This will not make you a pro overnight, but it will make you realize why you should embrace R as a beginner, despite its steep learning curve.\nListen, folks: R isn‚Äôt rocket science.\nI‚Äôm neither a programmer nor a coder, but I conduct all my statistical analysis in R. The possibilities and capacities of R never cease to amaze me.\nIn 2019, I approached R for its data visualization capabilities. I was fascinated by the beautiful and insightful graphs I could create. But as I delved deeper, I discovered R‚Äôs true potential: reproducibility.\nTo keep things simple, I would define reproducibility in the context of this blog as the ability to recreate an analysis you did by anyone, anywhere, at any time. This is the essence of R. I wrote a blog post on how conducting reproducible research even as a beginner can be a game-changer.\nViewing R as difficult software that requires coding, and feeling threatened by its steep learning curve, is why you make no progress. Approaching R for its reproducibility capabilities is the key to unlocking its potential as a beginner. Once this parallel world opens, you never want to go back.\nR stands out among other software due to its strong emphasis on reproducibility. Unlike many other tools, R allows you to document every step of your analysis process within scripts, ensuring that your work can be exactly replicated by anyone, anywhere, at any time. This transparency and accuracy are vital for robust data analysis and scientific research.\nI offer 3 best practices and 3 mistakes to avoid to embrace reproducibility as an R beginner:"
  },
  {
    "objectID": "posts/2024-07-02-rforreproducibility/rforreproducibility.html#best-practices",
    "href": "posts/2024-07-02-rforreproducibility/rforreproducibility.html#best-practices",
    "title": "From Charts to Consistency: My R Journey to Reproducibility",
    "section": "3 Best Practices",
    "text": "3 Best Practices\n\nClarify Code with Comments: Always comment your code and document each step to ensure anyone can understand and reproduce your analysis. Writing a log is a much-needed practice during the initial stages of analysis. If you are keen to develop a logging practice, read my blog post on logging using the logr\nUse Separate Scripts for Each Task: Organize your work by creating different scripts for data cleaning, analysis, and visualization. This practice keeps your project organized and makes it easier to track and debug your code. It also allows you to reuse and share specific parts of your workflow with others, enhancing collaboration and efficiency.\nTreat Errors as Opportunities: This can be incredibly frustrating when you start with R. But I recall one of my friend‚Äôs words - Welcome mistakes! When you encounter errors, use them as chances to improve your code and make it more robust."
  },
  {
    "objectID": "posts/2024-07-02-rforreproducibility/rforreproducibility.html#mistakes-to-avoid",
    "href": "posts/2024-07-02-rforreproducibility/rforreproducibility.html#mistakes-to-avoid",
    "title": "From Charts to Consistency: My R Journey to Reproducibility",
    "section": "3 Mistakes to Avoid",
    "text": "3 Mistakes to Avoid\n\nNot Using Projects: Always use R projects to keep your work organized and paths relative. By using R projects, you maintain a structured workspace that helps avoid confusion and errors related to file paths. It also ensures that your scripts are portable and can be easily shared or transferred without breaking dependencies. If you are new to projects in R, read here to know more.\nEditing Data Outside of R: Avoid modifying your data in other software. Keep all data manipulation within your R scripts. This ensures that all changes are documented and reproducible, maintaining the integrity of your workflow. It also allows for easier tracking of data transformations and provides a clear audit trail for verification and troubleshooting.\nNot Using Relative Paths: Using relative paths ensures that your scripts will work on any system without needing modifications. The here package simplifies path management, making your project more robust and easier to share. For more details on how to implement this, read my blog post on the here package here.\n\nI am a staunch advocate for reproducibility. I believe that reproducibility is a Non-Negotiable Imperative for Data Science. Embracing R as a tool for reproducibility changes the game for beginners and transforms your approach to data analysis."
  },
  {
    "objectID": "posts/2024-07-02-rforreproducibility/rforreproducibility.html#one-thing-for-approaching-r-as-a-beginner",
    "href": "posts/2024-07-02-rforreproducibility/rforreproducibility.html#one-thing-for-approaching-r-as-a-beginner",
    "title": "From Charts to Consistency: My R Journey to Reproducibility",
    "section": "One Thing for approaching R as a beginner",
    "text": "One Thing for approaching R as a beginner\n\nEmbrace R as a tool for reproducibility. By centering your efforts on reproducibility, you‚Äôll produce more robust and shareable work."
  },
  {
    "objectID": "posts/2024-10-09-beginningwithrepro/beginningwithrepro.html",
    "href": "posts/2024-10-09-beginningwithrepro/beginningwithrepro.html",
    "title": "Beginning with reproducibility in mind",
    "section": "",
    "text": "In this post, I argue why as a beginner, you should start with reproducibility in mind while using R.\nI know your goal as a researcher is just to get the project done‚Äîcompletion first, quality later. This is where we all began. Just like learning the alphabet, we started slowly. But once we learned the alphabet, we wanted to build words. There is a natural traction to do that.\nWhen you start in R, with just the ‚ÄúABCs,‚Äù you will gain strength and confidence to move forward. You will also notice that there are flaws in your workflows, stumbling blocks, and accumulating files that deteriorate your further learning. The more you learn, the more you create, and the more .r files and outputs you generate. You can do R now, but it is not enjoyable‚Äîthe initial honeymoon phase has ended.\nWhile as beginners, we just wanted to get the code out to produce the plot we wanted, a reproducible researcher, however, thinks differently. From the beginning, they plan, conduct, and wrap up their analysis with reproducibility in mind. Why? Because it helps them grow, allows for improvement, and creates workflows they can scale and build upon.\nHere, I will list the common problems encountered in R as a beginner without reproducibility and later introduce a minimal viable reproducible workflow to start. You can expand it as necessary."
  },
  {
    "objectID": "posts/2024-10-09-beginningwithrepro/beginningwithrepro.html#common-beginner-problems-without-reproducibility",
    "href": "posts/2024-10-09-beginningwithrepro/beginningwithrepro.html#common-beginner-problems-without-reproducibility",
    "title": "Beginning with reproducibility in mind",
    "section": "Common Beginner Problems without Reproducibility",
    "text": "Common Beginner Problems without Reproducibility\n\nAccumulating many files in various formats\nWithout a structured system, you end up with a mess of .R, .Rmd, .docx, .qmd, .png files scattered everywhere, often with vague names like rplot1.png, script1.R, script2.R. You‚Äôll never want to revisit these chaotic files.\n\n\n\nCredit: Photo by Ron Lach\n\n\n\n\nMessing up raw data\nIf you accidentally modify the raw data without proper backups, you may find yourself needing to re-import it or redo everything from scratch.\n\n\nCode fails on different systems\nYou write code that works on your machine, but it doesn‚Äôt run properly on another system or when integrated into an .Rmd or Quarto file.\n\n\nDifficulties tracking down code segments\nWith long scripts, you often lose track of where specific functions, like renaming variables, are located. Searching doesn‚Äôt help when the code is poorly organized.\n\n\nMultiple data intermediates\nYou may end up with various versions of data and analysis files saved without knowing which one is most current or relevant.\n\n\n\nCredit: Photo by Van Anh Nguyen"
  },
  {
    "objectID": "posts/2024-10-09-beginningwithrepro/beginningwithrepro.html#how-basic-reproducibility-principles-address-these-problems",
    "href": "posts/2024-10-09-beginningwithrepro/beginningwithrepro.html#how-basic-reproducibility-principles-address-these-problems",
    "title": "Beginning with reproducibility in mind",
    "section": "How Basic Reproducibility Principles Address These Problems",
    "text": "How Basic Reproducibility Principles Address These Problems\n\nWorking in Projects\n\nOrganizing your work into projects keeps things simpler. If you need to refer to scripts from other projects, you can still open them in RStudio without mixing files.\nThis approach prevents you from accumulating unrelated files in one chaotic directory, which makes revisiting projects feel overwhelming. Starting clean with well-organized project folders helps.\n\n\n\n\nYou have one project for each analysis; Credit: Photo by Andrea Piacquadio\n\n\n\n\nConsistent Folder Structures (Separate Raw and Derived Data)\n\nNavigating your files becomes easier, and you‚Äôll always know where to find the raw and processed data.\nKeeping raw data separate helps avoid accidental modifications. You can update your data cleaning scripts while keeping the original data intact‚Äîan essential principle.\n\n\n\n\nCredit: Photo by Pixabay\n\n\n\n\nUsing here::here() for File Paths\nThis approach ensures that your project can run on different devices and systems without breaking due to absolute file paths. When you use R Markdown or Quarto, your code will function across platforms without needing major adjustments.\n\n\n\nCredit: Photo by George Pak\n\n\n\n\nWriting Separate Scripts for Different Tasks\nBreaking your code into modular scripts makes it easier to debug. You‚Äôll always know which script to edit when something needs fixing.\n\n\nAvoid Saving Output Files\nWhile it may seem counterintuitive, the goal is to avoid saving outputs like graphs and tables. Instead, focus on saving the code that generates them. Think of the code as the recipe‚Äîthe ‚Äúcooking‚Äù only takes a few minutes, and you can always reproduce your results quickly when needed.\nBy following these reproducibility principles, you can avoid common pitfalls, improve your workflow, and build projects that are easier to manage and scale.\n\n\n\nCredit: Photo by Breakingpic"
  },
  {
    "objectID": "posts/2024-10-21-splitnonreproducibility/split-nonreproducibility.html",
    "href": "posts/2024-10-21-splitnonreproducibility/split-nonreproducibility.html",
    "title": "Lessons from a Splint: How Non-Reproducibility Hurts Science",
    "section": "",
    "text": "Video\nPost summary by the author\n\n\n\nIf a method can‚Äôt be followed, it‚Äôs as good as not shared\n\n\nThe Unspoken Pain of Non-Reproducibility\nAll these years, I have extensively discussed the importance of reproducibility in research, yet I have seldom highlighted the significant frustration and setbacks caused by non-reproducibility. Nick Milo refers to ‚Äúinfo pain‚Äù as the overwhelming feeling of being inundated with too much information. In a similar vein, I describe ‚Äúnon-reproducibility pain‚Äù as a tangible and exasperating experience‚Äîone I recently encountered firsthand. This frustration underscores the very essence of reproducibility, illustrating why it is not merely a technicality in research, but a crucial aspect of scientific integrity.\n\n\nA Real-Life Experience: The Splint That Couldn‚Äôt Be Used\nMy mom developed hallux valgus, or a deviated great toe, and we bought a splint for her. It came with an information booklet, but we couldn‚Äôt decipher how to use the product properly. All we saw was an assembled image of how it should be worn, but the information booklet only added to the confusion. It was filled with details that were difficult to follow in practice. The hinge on the splint kept moving when we tried it on her foot, and we weren‚Äôt sure whether the hinge should be on the side or above the toe. Finally, we gave up on the booklet and figured it out ourselves. Still, we had issues managing the straps, and after we thought we had everything set up, my mom complained of pain from the strap scraping her skin.\n\n\nThe Parallel to Research: When Methods Fail Us\nThis experience mirrors a common issue in research: the methods sections we write often fail to consider whether others can follow and replicate our procedures. Just as the splint‚Äôs instructions were unclear, leaving us frustrated, poorly written methods in research create barriers for others attempting to reproduce results. If we don‚Äôt keep the needs of the reader in mind‚Äîsomeone who may be unfamiliar with the work‚Äîit becomes nearly impossible for them to replicate the study. Ultimately, methods that are not accessible and explicit undermine the very purpose of sharing research.\n\n\nThe Need for Explicit Methods in Research\n\nThe primary goal of writing research papers is to allow others to learn from, build on, and replicate our work.\n\nTo achieve this, the methods section must be explicit‚Äîdetailed enough that even someone new to the subject can understand and independently follow the procedure. Clarity in writing is crucial, not just in outlining the methods but also in documenting the analysis. Both aspects must be reproducible, ensuring that others‚Äîand even our future selves‚Äîcan retrace the steps with precision. Without this level of transparency, the value of our research is diminished, as its core purpose‚Äîreproducibility‚Äîremains unmet.\n\n\nLogbooks: A Simple Solution to a Complex Problem\nA detailed logbook offers a simple yet powerful solution to the challenges of reproducibility. By documenting errors, solutions, and key decisions throughout the analysis, researchers create a comprehensive guide that makes it easier to retrace steps and replicate findings. &gt; The process requires some mindful stops: periodically pausing to summarize the key points in the logbook, ensuring nothing crucial is overlooked.\nThis logbook can take many forms, from a basic text file (.txt) to more specialized formats like .rmd or Quarto files in R. Personally, I prefer a minimalist, handwritten logbook to clearly distinguish it from other analysis documents.\n\n\n\nA peek into my logbook\n\n\nBefore I write my methods section, I simply consult my logbook to recall the steps taken, the decisions made, and the rationale behind them. This practice not only enhances reproducibility but also serves as a valuable resource for future projects by us and others. By investing time in maintaining a logbook, we invest in the integrity and longevity of our research.\n\nI wrote a post on using the logr package for logging my analysis on the go. Read it here\n\n\n\nWriting for Others\nConsider the First-Time Reader Just as the splint manufacturer likely intended for their product to be user-friendly, they failed to ensure that the instructions were clear for a first-time user. The booklet seemed written by someone already familiar with the product, overlooking the needs of new customers. A simple quality check‚Äîgiving the instructions to someone unfamiliar with the splint‚Äîcould have exposed its flaws. In the same way, when writing research logs and methods, we must always consider the perspective of those encountering the information for the first time. This ensures that our work is accessible and reproducible, which is critical to advancing science. Ultimately, reproducibility should always be the goal.\n\nResearch Isn‚Äôt Done Until It‚Äôs Reproducible!\n\n\n\n\nLogbook Photo by ALTEREDSNAPS"
  },
  {
    "objectID": "posts/2024-12-02-cooking/cooking-repro.html",
    "href": "posts/2024-12-02-cooking/cooking-repro.html",
    "title": "Reproducible Analysis Pipeline is akin to Cooking: A Simplified Guide",
    "section": "",
    "text": "You might have read earlier in my blog about how reproducibility relates to rasam. Today, I came up with another example after reading Reproducible Research in Practice (Kitzes, Turek, and Deniz 2018), an excellent book.\nWhen you decide to cook something, what do you do?\n\nYou buy groceries and bring them home.\nYou prepare them.\nYou cook them.\n\nSimilarly, reproducible pipelines have three major steps:\n\nImporting your data.\nCleaning and preparing the data for analysis.\nConducting the data analysis.\n\n\n\n\nReproducible data analysis is akin to cooking (Viz by Soundarya)\n\n\nBut it doesn‚Äôt stop there!\nWhen you cook, there‚Äôs often a recipe‚Äîa written guide. This recipe is akin to writing scripts for how your analysis was conducted. With a recipe, you can recreate your dish. Similarly, with scripts, you can recreate your analysis.\nNow, imagine doing this without a recipe. It‚Äôd be chaotic! But when you hand over the recipe card, others can reproduce your dish. Likewise, when you share your scripts, others can reproduce your analysis. Of course, you‚Äôd need to provide the same groceries too‚Äîjust like reproducible analysis requires you to share the data alongside your scripts.\n\n\n\nScripts are recipe cards (Viz by Soundarya)\n\n\nLastly, let‚Äôs talk about tidying up. When cooking, you clear the clutter‚Äîcleaning the workspace so you‚Äôre ready for the next task. In data analysis, this is like closing your session with a clean workspace, leaving only the scripts and data ready for use. This ensures the next analysis uses the most recent data and scripts, much like making sure your meal uses fresh ingredients and the latest recipe.\n\n\n\n\nReferences\n\nKitzes, Justin, Daniel Turek, and Fatma Deniz, eds. 2018. The Practice of Reproducible Research: Case Studies and Lessons from the Data-Intensive Sciences. University of California Press."
  },
  {
    "objectID": "posts/2024-12-26-analysisWorkflow/analysisWorkflow.html",
    "href": "posts/2024-12-26-analysisWorkflow/analysisWorkflow.html",
    "title": "Are You Ready When It Fails? Lessons from Network Outages in Reproducible Data Analysis",
    "section": "",
    "text": "At 10.30 AM on a crucial workday, my mobile network suddenly went dark‚Äîzero connectivity. My heart raced since I needed that connection for‚Ä¶ hmmm.. EVERYTHING. Eventually, we discovered that the outage affected the entire city, revealing a surprising vulnerability in our telecommunications infrastructure.\n\n\n\nPhoto by MART PRODUCTION\n\n\nI had always assumed companies distribute mobile towers spatially, meaning a problem in one area would only affect a small region. However, this incident exposed a critical insight: one hub controlled all city networks. This realization was alarming because if something goes wrong at the hub, it cascades through the entire system, affecting millions of users simultaneously.\nThis experience taught me a valuable lesson about system dependencies and failure points‚Äîa lesson that directly applies to how we should approach data analysis. In fact, the parallels between telecommunications infrastructure and data workflows became increasingly clear as I examined my own analytical processes.\nIn my data analysis workflow, I use three interdependent scripts that function like a chain of command. Script 1 performs data cleaning, taking raw data and outputting a cleaned version. Building on this foundation, Script 2 generates new variables, taking Script 1‚Äôs output as its input and producing a more refined dataset. Finally, Script 3 creates visualizations, using the clean data from Script 2 to generate meaningful insights.\nTo coordinate these components, I have a master script that automates the execution of all these scripts sequentially‚Äîsimilar to a ‚Äúhub‚Äù that coordinates all the mobile towers. While this workflow mirrors the mobile network‚Äôs centralized control system, I‚Äôve implemented a crucial difference: unlike the mobile network‚Äôs workflow, I don‚Äôt solely rely on the master script. Even if something goes wrong, I can still manually run each script (1, 2, and 3) individually.\nThe real issue arises if one of these scripts or their outputs is missing, as this would break the sequence. To mitigate this risk, I‚Äôve always ensured I store the outputs of Script 1, so Script 2 can proceed even if Script 1 is not re-run. Although this approach diverges from reproducibility principles, where data scientists typically discourage saving intermediate outputs and expect workflows to run seamlessly from start to finish, being prepared for unexpected failures has proven invaluable.\nTo protect my workflows, I implement three comprehensive strategies:\n\nUse a Master Script but Avoid Total Dependence\nWhile I use a master script for efficiency, I never trust it blindly. Each script is self-contained, clearly indicating its start and end points. When an error occurs, the scripts halt with a message, allowing me to pinpoint where the problem happened. For example, if I see the ‚Äúdata cleaning is completed‚Äù prompt, I know the issue lies in the next step, so I can directly revisit Script 3.\nSave Intermediate Outputs for Resilience\nAlthough it deviates from strict reproducibility principles, I save intermediate outputs as safety nets. To maintain updated datasets, I still run the master script to regenerate intermediates when raw data changes. This ensures consistency while providing a fallback option if the master script fails.\nBackup Raw Data in Multiple Locations\nI maintain backups of raw data in three different locations, ensuring I‚Äôm not left stranded in case of data loss or corruption.\n\n\nJust as a city‚Äôs mobile network relies on a central hub, many data analysis workflows depend on critical sequential steps. This vulnerability brings me to Murphy‚Äôs Law: Anything that can go wrong will go wrong. By embracing this mindset, we can better protect our analyses through careful preparation. The key questions become: Are we prepared if something fails? Do we have backups? Have we stored critical outputs in multiple locations? Addressing these concerns proactively often helps avoid disaster.\nThinking through these potential pitfalls before starting an analysis ensures preparedness. Once a solid plan is in place, it can serve as a template for future projects. The ultimate question remains: Are you prepared for when things go wrong?"
  }
]